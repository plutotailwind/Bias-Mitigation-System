{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2826fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9748368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import ssl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8326ac4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def LoadModelHUB():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
    "    tokenizer.padding_side = 'right' # to avoid the future warning\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
    "    return model, tokenizer\n",
    "\n",
    "def formatting_prompts_func(sentences):\n",
    "    out_sentences = []\n",
    "    for sentence in sentences['sentences']:\n",
    "        for text in sentence['sentence']:\n",
    "            out_sentences.append(text)\n",
    "\n",
    "    return out_sentences\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa102de",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def LoadModelUnsloth():\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "            \"mistralai/Mistral-7B-v0.1\", device_map=\"auto\", \n",
    "            max_seq_length = max_seq_length, dtype=None, load_in_4bit=True)\n",
    "\n",
    "    model = FastLanguageModel.get_peft_model(\n",
    "                    model, \n",
    "                    r = 16, \n",
    "                    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \n",
    "                        \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "                    lora_alpha = 16,\n",
    "                    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "                    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "                    use_gradient_checkpointing = True,\n",
    "                    random_state = 3407,\n",
    "                    use_rslora = False,  # We support rank stabilized LoRA\n",
    "                    loftq_config = None, # And LoftQ\n",
    "                    )\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e37a7ae",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def LoadDataset():\n",
    "    dataset = load_dataset(\"McGill-NLP/stereoset\", \"intersentence\", split='validation')\n",
    "    #dataset = dataset.map(formatting_prompts_func, remove_columns=[f for f in dataset.features if not f == 'sentences'],batched=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6332120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FineTuneModel(model, tokenizer, dataset):\n",
    "    trainer = SFTTrainer(model, train_dataset=dataset, \n",
    "            formatting_func=formatting_prompts_func, max_seq_length=512)\n",
    "\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cc6012",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def InitNLTK():\n",
    "    try:\n",
    "        _create_unverified_https_context = ssl._create_unverified_context\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    else:\n",
    "        ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5083ac",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def GetSynonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.add(lemma.name())\n",
    "    return list(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f64c5f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def InitBiasWords():\n",
    "    \"\"\"\n",
    "    Initialize the bias words in a list from a file\n",
    "    \"\"\"\n",
    "    bias_words = ['bad', 'black', 'slave']\n",
    "\n",
    "    return bias_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d565d1b5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def MitigateBias(text, bias_words):\n",
    "    words = text.split()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        synonyms = GetSynonyms(word)\n",
    "        unbiased_synonyms = [syn for syn in synonyms if syn not in bias_words]\n",
    "        if unbiased_synonyms:\n",
    "            new_word = unbiased_synonyms[0]\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "\n",
    "    return ' '.join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc609e3c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def HandleQuestion(model, tokenizer, dataset, bias_words):\n",
    "    pipe = pipeline(\"text-generation\", model=model, tokenizer = tokenizer)\n",
    "\n",
    "    question = input(\"Your question: \")\n",
    "    print(\"finding a good answer for your question, please wait,...\\n\")\n",
    "    answers = pipe(question, do_sample=True, max_new_tokens=100, \n",
    "            temperature=0.7, top_k=50, top_p=0.95, num_return_sequences=1)\n",
    "\n",
    "    if not bias_words:\n",
    "        output = answers[0]['generated_text']\n",
    "    else:\n",
    "        output = MitigateBias(answers[0]['generated_text'])\n",
    "\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4a2bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    InitNLTK() # to remove the bias words\n",
    "    bias_words = InitBiasWords() # list of bias words present in our dataset\n",
    "    model, tokenizer = LoadModelUnsloth() # Load the mistrel 7b ai model\n",
    "    dataset = LoadDataset() # load our dataset\n",
    "    FineTuneModel(model, tokenizer, dataset)\n",
    "\n",
    "    HandleQuestion(model, tokenizer, dataset, bias_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d37e5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
